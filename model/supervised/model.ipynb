{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbenip/tetris-ai/blob/main/model/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/bbenip/tetris-ai.git"
      ],
      "metadata": {
        "id": "-tgtAFQyx5IT",
        "outputId": "0dc03f03-1d9f-40b6-a7c2-5920dc5dda50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'tetris-ai'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 137 (delta 17), reused 9 (delta 2), pack-reused 93\u001b[K\n",
            "Receiving objects: 100% (137/137), 36.42 MiB | 26.51 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run data pre-proccessing, extracting json data for games.rar and building data.hdf5"
      ],
      "metadata": {
        "id": "QTE9A__pJj1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-io\n",
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgsSPQRpHvAo",
        "outputId": "7c736bd1-8978-42d2-debc-55d14d15e765"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-io in /usr/local/lib/python3.10/dist-packages (0.34.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.34.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-io) (0.34.0)\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/tetris-ai/data/modify.ipynb"
      ],
      "metadata": {
        "id": "SxzUMYT-yend",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "1eca7626-1de0-48d8-95db-c48e2555bea3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Processing file: 8171/8172'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<HDF5 dataset \"X_active_block\": shape (2558757,), type \"<i8\">\n",
            "<HDF5 dataset \"X_block_pos\": shape (2558757, 2), type \"<i8\">\n",
            "<HDF5 dataset \"X_block_rot\": shape (2558757,), type \"<i8\">\n",
            "<HDF5 dataset \"X_grid\": shape (2558757, 20, 10), type \"|i1\">\n",
            "<HDF5 dataset \"X_held_block\": shape (2558757,), type \"<i8\">\n",
            "<HDF5 dataset \"Y\": shape (2558757,), type \"<i8\">\n",
            "<HDF5 dataset \"X_active_block\": shape (288380,), type \"<i8\">\n",
            "<HDF5 dataset \"X_block_pos\": shape (288380, 2), type \"<i8\">\n",
            "<HDF5 dataset \"X_block_rot\": shape (288380,), type \"<i8\">\n",
            "<HDF5 dataset \"X_grid\": shape (288380, 20, 10), type \"|i1\">\n",
            "<HDF5 dataset \"X_held_block\": shape (288380,), type \"<i8\">\n",
            "<HDF5 dataset \"Y\": shape (288380,), type \"<i8\">\n",
            "<HDF5 dataset \"X_active_block\": shape (2558757,), type \"<i8\">\n",
            "<HDF5 dataset \"X_block_pos\": shape (2558757, 2), type \"<i8\">\n",
            "<HDF5 dataset \"X_block_rot\": shape (2558757,), type \"<i8\">\n",
            "<HDF5 dataset \"X_grid\": shape (2558757, 20, 10), type \"|i1\">\n",
            "<HDF5 dataset \"X_held_block\": shape (2558757,), type \"<i8\">\n",
            "<HDF5 dataset \"Y\": shape (2558757,), type \"<i8\">\n",
            "<HDF5 dataset \"X_active_block\": shape (288380,), type \"<i8\">\n",
            "<HDF5 dataset \"X_block_pos\": shape (288380, 2), type \"<i8\">\n",
            "<HDF5 dataset \"X_block_rot\": shape (288380,), type \"<i8\">\n",
            "<HDF5 dataset \"X_grid\": shape (288380, 20, 10), type \"|i1\">\n",
            "<HDF5 dataset \"X_held_block\": shape (288380,), type \"<i8\">\n",
            "<HDF5 dataset \"Y\": shape (288380,), type \"<i8\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in dataset"
      ],
      "metadata": {
        "id": "-ksboZoiKPyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import os\n",
        "\n",
        "DATA_DIR = \"/content/tetris-ai/data\"\n",
        "TRAIN_DATASET_FILE_NAME = \"train_data.hdf5\"\n",
        "TEST_DATASET_FILE_NAME = \"test_data.hdf5\"\n",
        "\n",
        "train_data_file = os.path.join(DATA_DIR, TRAIN_DATASET_FILE_NAME)\n",
        "test_data_file = os.path.join(DATA_DIR, TEST_DATASET_FILE_NAME)\n",
        "dataset_names = ['/X_held_block', '/X_active_block', '/X_block_pos', '/X_block_rot','/X_grid','/Y']\n",
        "\n",
        "train_data = [tfio.IODataset.from_hdf5(train_data_file, setName) for setName in dataset_names]\n",
        "test_data = [tfio.IODataset.from_hdf5(test_data_file, setName)  for setName in dataset_names]"
      ],
      "metadata": {
        "id": "Q1JzFbN_Djj1"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukX7-ycsHWVM",
        "outputId": "a8dde85a-7566-431b-a986-34e6630ab63e"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<HDF5IODataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>, <HDF5IODataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>, <HDF5IODataset element_spec=TensorSpec(shape=(2,), dtype=tf.int64, name=None)>, <HDF5IODataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>, <HDF5IODataset element_spec=TensorSpec(shape=(20, 10), dtype=tf.int8, name=None)>, <HDF5IODataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "RHt4hEGjxn9l"
      },
      "outputs": [],
      "source": [
        "#import data/data.hdf5\n",
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_held, train_active, train_pos, train_rot, train_grid, train_y = train_data\n",
        "test_held, test_active, test_pos, test_rot, test_grid, test_y = test_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_held)"
      ],
      "metadata": {
        "id": "PCV4mTgkPGzx",
        "outputId": "ab0d955c-2b41-49e1-93bc-2ba743986534",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<HDF5IODataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert scalar datapoints (heldBlock, activeBlock, blockRotation, nextMove) into 1-hot vector representations\n",
        "\n",
        "e.g.\n",
        "\n",
        ">\n",
        "\n",
        ">Currently Held Block ⟶ **4**<br>\n",
        ">Number of Block Types ⟶ **8** (including 0 for None)<br>\n",
        ">1-hot vector ⟶ **[0, 0, 0, 0, 1, 0, 0, 0]**<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "i3X7zs8qKyuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_held = train_held.map(lambda x: tf.one_hot(x, 8), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_active = train_active.map(lambda x: tf.one_hot(x, 8), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_rot = train_rot.map(lambda x: tf.one_hot(x, 4), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_y = train_y.map(lambda x: tf.one_hot(x, 10), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "print(train_held)"
      ],
      "metadata": {
        "id": "jlJCkMAplZ35",
        "outputId": "0e72daf4-331d-45ea-85d8-0a6d9c918048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_ParallelMapDataset element_spec=TensorSpec(shape=(8,), dtype=tf.float32, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_held = test_held.map(lambda x: tf.one_hot(x, 8), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_active = test_active.map(lambda x: tf.one_hot(x, 8), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_rot = test_rot.map(lambda x: tf.one_hot(x, 4), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_y =test_y.map(lambda x: tf.one_hot(x, 10), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "print(test_held)"
      ],
      "metadata": {
        "id": "bY1XahRFlhOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27144218-0530-488b-e822-bdeda9cdc80e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_ParallelMapDataset element_spec=TensorSpec(shape=(8,), dtype=tf.float32, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_non_zero_with_one(element):\n",
        "    condition = tf.math.not_equal(element, 0)\n",
        "    return tf.where(condition, np.int8(1), element)"
      ],
      "metadata": {
        "id": "_2K429XksscF"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_grid = train_grid.map(replace_non_zero_with_one, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_grid = test_grid.map(replace_non_zero_with_one, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "1yde40blC-wq"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine Datasets into one"
      ],
      "metadata": {
        "id": "McBzHB4dre5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataset = tf.data.Dataset.zip((train_held, train_active, train_pos, train_rot, train_grid), train_y)\n",
        "testDataset = tf.data.Dataset.zip((test_held, test_active, test_pos, test_rot, test_grid), test_y)"
      ],
      "metadata": {
        "id": "p6OoYg6creUd"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDataset = testDataset.batch(128)"
      ],
      "metadata": {
        "id": "zTIfx7OntGf8"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "FaP43HL6Mdn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Training Constants { run: \"auto\" }\n",
        "# @markdown Number of iterations over whole dataset\n",
        "EPOCHS = 10 # @param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "L5Qs3w7Et50H"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#Pass in hp to tune hyperparameters (# of nodes, activation function)\n",
        "def build_model(hp):\n",
        "  # Define input layers for each type of input\n",
        "  cnn_input = Input((20,10,1))\n",
        "  heldBlock_input = Input((8))\n",
        "  activeBlock_input = Input((8))\n",
        "  rotation_input = Input((4))\n",
        "  position_input = Input((2))\n",
        "\n",
        "  x = Conv2D(hp.Int('cnn_units_1', min_value=32, max_value=512, step=32), (5, 5), strides=(5,5), padding=\"same\", activation=hp.Choice('activation', values=['relu', 'sigmoid', 'tanh']))(cnn_input)\n",
        "  x = Conv2D(hp.Int('cnn_units_2', min_value=32, max_value=512, step=32), (3, 3), strides=(2,2), padding=\"same\", activation=hp.Choice('activation', values=['relu', 'sigmoid', 'tanh']))(x)\n",
        "  x = Conv2D(hp.Int('cnn_units_3', min_value=32, max_value=512, step=32), (3, 3), padding=\"same\", activation=hp.Choice('activation', values=['relu', 'sigmoid', 'tanh']))(x)\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  # Concatenate all the branches\n",
        "  combined = concatenate([x, heldBlock_input, activeBlock_input, rotation_input, position_input])\n",
        "  # Add more layers if needed\n",
        "  combined = Dense(hp.Int('dense_units_4', min_value=32, max_value=512, step=32), activation=hp.Choice('activation', values=['relu', 'sigmoid', 'tanh']))(combined)\n",
        "  combined = Dense(hp.Int('dense_units_5', min_value=32, max_value=512, step=32), activation=hp.Choice('activation', values=['relu', 'sigmoid', 'tanh']))(combined)\n",
        "  combined = Dense(hp.Int('dense_units_6', min_value=32, max_value=512, step=32), activation=hp.Choice('activation', values=['relu', 'sigmoid', 'tanh']))(combined)\n",
        "  output = Dense(10, activation='softmax')(combined)  # Replace 'output_dim' with the number of output classes or neurons\n",
        "\n",
        "  # Create the model\n",
        "  model = Model(inputs=[heldBlock_input, activeBlock_input, position_input, rotation_input, cnn_input], outputs=output)\n",
        "  from keras.optimizers import Adam\n",
        "  # Compile the model\n",
        "  model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "Gb_3AdfIYCt5"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search for best hyperparameters"
      ],
      "metadata": {
        "id": "pjQyt-i0nh2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  { form-width: \"256px\" }\n",
        "# @title  { form-width: \"128px\" }\n",
        "# @title  { run: \"auto\", form-width: \"30px\" }\n",
        "from kerastuner.tuners import Hyperband\n",
        "\n",
        "overwrite = True # @param {type:\"boolean\"}\n",
        "\n",
        "tuner = Hyperband(\n",
        "    hypermodel=build_model,\n",
        "    objective='val_accuracy',\n",
        "    overwrite=overwrite,\n",
        "    max_epochs=EPOCHS,\n",
        "    directory='/content/tuning',  # Directory to save the results\n",
        "    project_name='tetris_tuning'\n",
        ")"
      ],
      "metadata": {
        "id": "ot8jz9zqXjbf"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(\n",
        "    x=trainDataset.shard(num_shards=8, index=0).batch(256).prefetch(tf.data.AUTOTUNE).cache(),\\\n",
        "    epochs=EPOCHS,\\\n",
        "    validation_data=testDataset,\\\n",
        "    use_multiprocessing=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRbh8Z_wfr9K",
        "outputId": "ee51905c-9968-4b89-b8de-03f3e90525bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 03m 48s]\n",
            "val_accuracy: 0.3106907606124878\n",
            "\n",
            "Best val_accuracy So Far: 0.3174145221710205\n",
            "Total elapsed time: 00h 55m 38s\n",
            "\n",
            "Search: Running Trial #21\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "96                |512               |cnn_units_1\n",
            "tanh              |tanh              |activation\n",
            "448               |160               |cnn_units_2\n",
            "160               |288               |cnn_units_3\n",
            "64                |512               |dense_units_4\n",
            "160               |64                |dense_units_5\n",
            "160               |64                |dense_units_6\n",
            "4                 |10                |tuner/epochs\n",
            "0                 |4                 |tuner/initial_epoch\n",
            "1                 |2                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "Epoch 1/4\n",
            "1250/1250 [==============================] - 44s 33ms/step - loss: 1.5406 - accuracy: 0.3008 - val_loss: 1.4979 - val_accuracy: 0.2999\n",
            "Epoch 2/4\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.4723 - accuracy: 0.3100"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build model using optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "best_model = build_model(best_hps)"
      ],
      "metadata": {
        "id": "K4t2tXM_cmvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = best_model.fit(\n",
        "    trainDataset.batch(256).prefetch(tf.data.AUTOTUNE),\\\n",
        "    epochs=25,\\\n",
        "    validation_data=testDataset,\\\n",
        "    use_multiprocessing=True,\\\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)]\n",
        ")"
      ],
      "metadata": {
        "id": "sRvJerT4nqyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf1.close()\n",
        "hf2.close()"
      ],
      "metadata": {
        "id": "Do7QMtJN8ebI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fjPZJa9OyrnS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}