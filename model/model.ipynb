{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#import data/data.hdf5\n","import h5py\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split\n","DATA_DIR = \"data\"\n","DATASET_FILE_NAME = \"data.hdf5\"\n","def load_dataset():\n","    data_file = os.path.join(DATA_DIR, DATASET_FILE_NAME)\n","    hf = h5py.File(data_file, 'r')\n","    X_grids = np.array(hf.get('X_grids'))\n","    X_scalars = np.array(hf.get('X_scalars'))\n","    Y = np.array(hf.get('Y'))\n","\n","    return X_grids, X_scalars, Y\n","\n","dataset = load_dataset()\n","\n","'''\n","grid 20x10x? vector\n","heldBlock 8 vector 1-hot\n","activeBlock 7 vector 1-hot\n","blockPos 2 vector\n","blockRot 4 vector 1-hot\n","nextMove 10 vector 1-hot\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#reshape X_grids into 3-D array where each entry is a 20x10 grid\n","def reshape_X_grids(X_grids):\n","    X_grids_reshaped = np.zeros((X_grids.shape[0], 20, 10))\n","    for i in range(X_grids.shape[0]):\n","        X_grids_reshaped[i] = X_grids[i].reshape(20, 10)\n","    return X_grids_reshaped\n","\n","dataset[0] = reshape_X_grids(dataset[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#split dataset into train and test set by random\n","def split_dataset(X_grids, X_scalars, Y):\n","    X_grids_train, X_grids_test, X_scalars_train, X_scalars_test, Y_train, Y_test = train_test_split(X_grids, X_scalars, Y, test_size=0.2, random_state=42)\n","    return ((X_grids_train, X_scalars_train, Y_train), (X_grids_test, X_scalars_test, Y_test))\n","\n","train_dataset, test_dataset = split_dataset(X_grids, X_scalars, Y)\n","print(test_dataset[2].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert currentBlock scalar into N-hot vector\n","def scalarToVector(scalar, size):\n","    vector = np.zeros(size)\n","    vector[scalar] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, concatenate\n","from tensorflow.keras.models import Model\n","\n","# Define input layers for each type of input\n","cnn_input = Input(shape=(20, 10, 1))\n","heldBlock_input = Input(shape=(8,))\n","activeBlock_input = Input(shape=(7,))\n","rotation_input = Input(shape=(4,))\n","position_input = Input(shape=(2,))\n","\n","# CNN branch\n","x = Conv2D(32, (3, 3), activation='relu')(cnn_input)\n","x = Flatten()(x)\n","\n","# Branch for 8-vector input\n","x2 = Dense(16, activation='relu')(eight_vector_input)\n","\n","# Branch for 7-vector input\n","x3 = Dense(16, activation='relu')(seven_vector_input)\n","\n","# Branch for 4-vector input\n","x4 = Dense(16, activation='relu')(four_vector_input)\n","\n","# Branch for 2-vector input\n","x5 = Dense(16, activation='relu')(two_vector_input)\n","\n","# Concatenate all the branches\n","combined = concatenate([x, x2, x3, x4, x5])\n","\n","# Add more layers if needed\n","combined = Dense(64, activation='relu')(combined)\n","output = Dense(10, activation='softmax')(combined)  # Replace 'output_dim' with the number of output classes or neurons\n","\n","# Create the model\n","model = Model(inputs=[cnn_input, eight_vector_input, seven_vector_input, four_vector_input, two_vector_input], outputs=output)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","#model.fit([cnn_data, eight_vector_data, seven_vector_data, four_vector_data, two_vector_data], labels, epochs=epochs, batch_size=batch_size)\n","\n","def create_model():\n","    pass\n","    \n","\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPQ0cPcKezxeVLg8v0cixsH","name":"Untitled"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}
